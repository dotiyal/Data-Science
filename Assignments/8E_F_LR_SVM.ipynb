{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HExLQrE4ZxR"
   },
   "source": [
    "<h1><font color='blue'> 8E and 8F: Finding the Probability P(Y==1|X)</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LuKrFzC4ZxV"
   },
   "source": [
    "<h2><font color='Geen'> 8E: Implementing Decision Function of SVM RBF Kernel</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wES-wWN4ZxX"
   },
   "source": [
    "<font face='Helvetica' size=3>After we train a kernel SVM model, we will be getting support vectors and their corresponsing coefficients $\\alpha_{i}$\n",
    "\n",
    "Check the documentation for better understanding of these attributes:<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "<img src='https://i.imgur.com/K11msU4.png' width=500>\n",
    "\n",
    "As a part of this assignment you will be implementing the ```decision_function()``` of kernel SVM, here decision_function() means based on the value return by ```decision_function()``` model will classify the data point either as positive or negative\n",
    "\n",
    "Ex 1: In logistic regression After traning the models with the optimal weights $w$ we get, we will find the value $\\frac{1}{1+\\exp(-(wx+b))}$, if this value comes out to be < 0.5 we will mark it as negative class, else its positive class\n",
    "\n",
    "Ex 2: In Linear SVM After traning the models with the optimal weights $w$ we get, we will find the value of $sign(wx+b)$, if this value comes out to be -ve we will mark it as negative class, else its positive class.\n",
    "\n",
    "Similarly in Kernel SVM After traning the models with the coefficients $\\alpha_{i}$ we get, we will find the value of \n",
    "$sign(\\sum_{i=1}^{n}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here $K(x_{i},x_{q})$ is the RBF kernel. If this value comes out to be -ve we will mark $x_{q}$ as negative class, else its positive class.\n",
    "\n",
    "RBF kernel is defined as: $K(x_{i},x_{q})$ = $exp(-\\gamma ||x_{i} - x_{q}||^2)$\n",
    "\n",
    "For better understanding check this link: https://scikit-learn.org/stable/modules/svm.html#svm-mathematical-formulation\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z830CfMk4Zxa"
   },
   "source": [
    "## Task E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuBxHiCQ4Zxc"
   },
   "source": [
    "> 1. Split the data into $X_{train}$(60), $X_{cv}$(20), $X_{test}$(20)\n",
    "\n",
    "> 2. Train $SVC(gamma=0.001, C=100.)$ on the ($X_{train}$, $y_{train}$)\n",
    "\n",
    "> 3. Get the decision boundry values $f_{cv}$ on the $X_{cv}$ data  i.e. ` `$f_{cv}$ ```= decision_function(```$X_{cv}$```)```  <font color='red'>you need to implement this decision_function()</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "fCgMNEvI4Zxf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ANUNIqCe4Zxn"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=5000, n_features=5, n_redundant=2,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHie1zqH4Zxt"
   },
   "source": [
    "### Pseudo code\n",
    "\n",
    "clf = SVC(gamma=0.001, C=100.)<br>\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "<font color='green'>def</font> <font color='blue'>decision_function</font>(Xcv, ...): #use appropriate parameters <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='green'>for</font> a data point $x_q$ <font color='green'>in</font> Xcv: <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='grey'># code to implement $(\\sum_{i=1}^{\\text{all the support vectors}}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here the values $y_i$, $\\alpha_{i}$, and $intercept$ can be obtained from the trained model</font><br>\n",
    "   <font color='green'>return</font> <font color='grey'><i># the decision_function output for all the data points in the Xcv</i></font>\n",
    "    \n",
    "fcv = decision_function(Xcv, ...)  <i># based on your requirement you can pass any other parameters </i>\n",
    "\n",
    "<b>Note</b>: Make sure the values you get as fcv, should be equal to outputs of clf.decision_function(Xcv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "h43kDT3M41u5"
   },
   "outputs": [],
   "source": [
    "# you can write your code here\n",
    "# split the data into train test cv\n",
    "x, x_test, y, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8)\n",
    "X_train, x_cv, y_train, y_cv = train_test_split(x, y, test_size = 0.25, train_size = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2ihOJfv_alr",
    "outputId": "d7afc7e3-a8ca-4514-ef8e-87542bfe793d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (3000, 5)\n",
      "X_test shape: (1000, 5)\n",
      "X_cv shape:  (1000, 5)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape:', x_test.shape)\n",
    "print('X_cv shape: ', x_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3gnS8SKc0Vh4",
    "outputId": "540fc5f9-db8d-495e-fbea-43aa8784f988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dual_coeff shape:  (539,)\n",
      "support_vectors:  (539, 5)\n",
      "intercept:  [1.11810095]\n"
     ]
    }
   ],
   "source": [
    "# fit RBF SVC to X_train data\n",
    "clf = SVC(gamma=0.001, C=100.)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "dual_coeff = clf.dual_coef_[0]\n",
    "support_vectors = clf.support_vectors_\n",
    "\n",
    "print('dual_coeff shape: ', dual_coeff.shape)\n",
    "print('support_vectors: ', support_vectors.shape)\n",
    "\n",
    "\n",
    "intercept = clf.intercept_\n",
    "print('intercept: ', intercept)\n",
    "\n",
    "# sv_indices = svc_clf.support_\n",
    "# sv_dual_coeff = svc_clf.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "STLbXxhh0Vh8"
   },
   "outputs": [],
   "source": [
    "def decision_function(X_cv):\n",
    "    sample_output_rbf = 0\n",
    "    y_predicted = []\n",
    "    gamma = clf._gamma\n",
    "    \n",
    "    for x_q in X_cv:\n",
    "        kernel_sum = 0\n",
    "        for i in range(len(support_vectors)):\n",
    "            squared_distance = (np.linalg.norm(support_vectors[i] - x_q)**2)\n",
    "            rbf_k = np.exp(-gamma * (squared_distance))\n",
    "            kernel_sum += dual_coeff[i] * rbf_k\n",
    "        sample_output_rbf = kernel_sum + intercept\n",
    "        y_predicted.append(sample_output_rbf[0])\n",
    "    \n",
    "    return np.array(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RuFOeLNq0Vh8",
    "outputId": "b34383e8-7099-4dab-8bd2-1471549184f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inbuilt_decision_function: first 5 elements:  [-2.85046596  1.49379945  0.27452972 -1.95842413  1.48706226]\n",
      "f_cv: first 5 elements:                       [-2.85046596  1.49379945  0.27452972 -1.95842413  1.48706226]\n"
     ]
    }
   ],
   "source": [
    "svm_decision_inbuilt_result_x_cv = clf.decision_function(x_cv)\n",
    "# svm_decision_inbuilt_result_x_cv = clf.decision_function(x_test)\n",
    "# svm_decision_inbuilt_result_x_test = clf.decision_function(x_test)\n",
    "# print('x_test.shape x', svm_decision_inbuilt_result_x_test.shape)\n",
    "\n",
    "print('inbuilt_decision_function: first 5 elements: ', svm_decision_inbuilt_result_x_cv[:5])\n",
    "\n",
    "f_cv = decision_function(x_cv)\n",
    "print('f_cv: first 5 elements:                      ', f_cv[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0bKCboN4Zxu"
   },
   "source": [
    "<h2><font color='Geen'> 8F: Implementing Platt Scaling to find P(Y==1|X)</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMn7OEN94Zxw"
   },
   "source": [
    "Check this <a href='https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a'>PDF</a>\n",
    "<img src='https://i.imgur.com/CAMnVnh.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0n5EFkx4Zxz"
   },
   "source": [
    "## TASK F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0HOqVJq4Zx1"
   },
   "source": [
    "\n",
    "> 4. Apply SGD algorithm with ($f_{cv}$, $y_{cv}$) and find the weight $W$ intercept $b$ ```Note: here our data is of one dimensional so we will have a one dimensional weight vector i.e W.shape (1,)``` \n",
    "\n",
    "> Note1: Don't forget to change the values of $y_{cv}$ as mentioned in the above image. you will calculate y+, y- based on data points in train data\n",
    "\n",
    "> Note2: the Sklearn's SGD algorithm doesn't support the real valued outputs, you need to use the code that was done in the `'Logistic Regression with SGD and L2'` Assignment after modifying loss function, and use same parameters that used in that assignment.\n",
    "<img src='https://i.imgur.com/zKYE9Oc.png'>\n",
    "if Y[i] is 1, it will be replaced with y+ value else it will replaced with y- value\n",
    "\n",
    "> 5. For a given data point from $X_{test}$, $P(Y=1|X) = \\frac{1}{1+exp(-(W*f_{test}+ b))}$ where ` `$f_{test}$ ```= decision_function(```$X_{test}$```)```, W and b will be learned as metioned in the above step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTY7z2bd4Zx2"
   },
   "source": [
    "__Note: in the above algorithm, the steps 2, 4 might need hyper parameter tuning, To reduce the complexity of the assignment we are excluding the hyerparameter tuning part, but intrested students can try that__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CM3odN1Z4Zx3"
   },
   "source": [
    "\n",
    "If any one wants to try other calibration algorithm istonic regression also please check these tutorials\n",
    "\n",
    "1. http://fa.bianp.net/blog/tag/scikit-learn.html#fn:1\n",
    "\n",
    "2. https://drive.google.com/open?id=1MzmA7QaP58RDzocB0RBmRiWfl7Co_VJ7\n",
    "\n",
    "3. https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a\n",
    "\n",
    "4. https://stat.fandom.com/wiki/Isotonic_regression#Pool_Adjacent_Violators_Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "l8y0d-2K0ViA"
   },
   "outputs": [],
   "source": [
    "# Randomly initializing weights (w) and intercept values (b)\n",
    "# dim - size of the w vector we want (or number of features or parameters in this case)\n",
    "\n",
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias\n",
    "        w :- weights, a numpy array\n",
    "        b :- bias, a scalar\n",
    "    '''\n",
    "    # initialize the weights to zeros array of (1, dim) dimensions\n",
    "    w = np.zeros_like(dim)\n",
    "    # initialize bias to zero\n",
    "    b = 0\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "mG7at2XHKBmH"
   },
   "outputs": [],
   "source": [
    "def get_calibrated_prob(Y):\n",
    "    n_positive = np.count_nonzero(Y)\n",
    "    n_negative = len(Y) - n_positive\n",
    "    calibrated_y_positive = (n_positive + 1) / (n_positive + 2)\n",
    "    calibrated_y_negative = 1 / (n_negative + 2) \n",
    "    return calibrated_y_positive, calibrated_y_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uG9RMLC_KEFw",
    "outputId": "bce9556b-5a94-458a-97cb-baf0b3736c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated_Y_positive(y_minus):  0.9989023051591658\n",
      "Calibrated_Y_negative(y_minus):  0.00047778308647873863\n"
     ]
    }
   ],
   "source": [
    "y_plus, y_minus = get_calibrated_prob(y_train) # new y_cv\n",
    "print(\"Calibrated_Y_positive(y_minus): \", y_plus)\n",
    "print(\"Calibrated_Y_negative(y_minus): \", y_minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "FC6PKqCL0ViA"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "    return 1.0/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "FEVDdZAy0ViA"
   },
   "outputs": [],
   "source": [
    "def logloss(y_true, y_pred):\n",
    "    sum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if (y_true[i] == 1):\n",
    "            sum += (y_plus * np.log10(y_pred[i])) + ((1 - y_plus) * np.log10(1 - y_pred[i]))\n",
    "        else:\n",
    "            sum += (y_minus * np.log10(y_pred[i])) + ((1 - y_minus) * np.log10(1 - y_pred[i]))\n",
    "    return -1 * (1 / len(y_true)) * sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "7t6wcjGF0ViB"
   },
   "outputs": [],
   "source": [
    "# make sure that the sigmoid function returns a scalar value, you can use dot function operation\n",
    "def gradient_dw(x, y, w, b, alpha, N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    dw = x * (y - sigmoid(np.dot(w, x) + b) - (alpha / N) * w)\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "mD9Eh9Ir0ViB"
   },
   "outputs": [],
   "source": [
    "#sb should be a scalar value\n",
    "def gradient_db(x,y,w,b):\n",
    "    '''In this function, we will compute gradient w.r.to b '''\n",
    "    \n",
    "    db = y - sigmoid(np.dot(w, x) + b)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "dbUSYM-m0ViB"
   },
   "outputs": [],
   "source": [
    "def train(X_train, y_train, X_test, y_test, epochs, alpha, eta0):\n",
    "    \n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "        \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    w, b = initialize_weights(X_train[0]) # Initialize the weights\n",
    "    N = len(X_train)\n",
    "\n",
    "    # write your code to perform SGD\n",
    "    for i in range(epochs):\n",
    "        train_pred = []\n",
    "        test_pred = []\n",
    "        for j in range(N):\n",
    "            dw = gradient_dw(X_train[j], y_train[j], w, b, alpha, N)\n",
    "            db = gradient_db(X_train[j], y_train[j], w, b)\n",
    "            w = w + (eta0 * dw)\n",
    "            b = b + (eta0 * db)\n",
    "        \n",
    "        for val in range(N):\n",
    "            train_pred.append(sigmoid(np.dot(w, X_train[val]) + b))\n",
    "        \n",
    "        loss1 = logloss(y_train, train_pred)\n",
    "        train_loss.append(loss1)\n",
    "        \n",
    "        for val in range(len(X_test)):\n",
    "            test_pred.append(sigmoid(np.dot(w, X_test[val]) + b))\n",
    "        \n",
    "        loss2 = logloss(y_test, test_pred)\n",
    "        test_loss.append(loss2)\n",
    "\n",
    "    return w, b, train_loss, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLOMftNO0ViC",
    "outputId": "f11f3473-7a4a-4f62-acdc-3c605e78b39c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized w:  1.2262837570003287\n",
      "optimized b:  -0.08525159184597207\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.0001\n",
    "eta0 = 0.0001\n",
    "epochs = 50\n",
    "optimized_w, optimized_b, cv_log_loss, test_log_loss = train(f_cv, y_cv, x_test, y_test, epochs, alpha, eta0)\n",
    "\n",
    "print('optimized w: ', optimized_w)\n",
    "print('optimized b: ', optimized_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "DjNZnrZ50ViC",
    "outputId": "8cdec69d-527d-4146-b17b-111a37c9beb0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array([i for i in range(0, 50)])\n",
    "\n",
    "cv_log_loss_arr = np.array(cv_log_loss)\n",
    "\n",
    "plt.plot(x, cv_log_loss_arr, '-b', label = 'CV log loss')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "\n",
    "plt.xlabel('Number of Epoch')\n",
    "plt.ylabel('Log Loss')\n",
    "\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e70hcvt0ViD",
    "outputId": "49a458b3-6a3b-401d-cc32-7f29916a8546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 elements proba_arr_f_test:  [0.053030871084574355, 0.9071291556839961, 0.015782121110546242, 0.01384003352266687, 0.01843754180189938]\n"
     ]
    }
   ],
   "source": [
    "f_test = decision_function(x_test)\n",
    "# print('Shape of custom_decision_function_result_x_test ', f_test.shape)\n",
    "\n",
    "proba_arr_f_test = []\n",
    "\n",
    "for i in f_test:\n",
    "    i_proba = sigmoid(np.dot(optimized_w, i) + optimized_b)\n",
    "    proba_arr_f_test.append(i_proba)\n",
    "\n",
    "print('First 5 elements proba_arr_f_test: ', proba_arr_f_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--iCPKwp34n4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "8E_F_LR_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
